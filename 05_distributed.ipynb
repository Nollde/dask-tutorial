{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://dask.readthedocs.io/en/latest/_images/dask_horizontal.svg\"\n",
    "     align=\"right\"\n",
    "     width=\"30%\"\n",
    "     alt=\"Dask logo\\\">\n",
    "\n",
    "# Distributed - spread your data and computation across a cluster\n",
    "\n",
    "As we covered at the beginning Dask has the ability to run work on multiple machines using the distributed scheduler.\n",
    "\n",
    "Until now we have actually been using the distributed scheduler for our work, but just on a single machine.\n",
    "\n",
    "When we instantiate a `Client()` object with no arguments it will attempt to locate a Dask cluster. It will check your local Dask config and environment variables to see if connection information has been specified. If not it will create an instance of `LocalCluster` and use that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Cluster\n",
    "\n",
    "Let's explore the `LocalCluster` object ourselves and see what it is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import LocalCluster, Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCluster()\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a cluster object will create a Dask scheduler and a number of Dask workers. If no arguments are specified then it will autodetect the number of CPU cores your system has and the amount of memory and create workers to appropriately fill that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our cluster object has attributes and methods which we can use to access information about our cluster. For instance we can get the log output from the scheduler and all the workers with the `get_logs()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the url that the Dask dashboard is being hosted at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.dashboard_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for Dask to use our cluster we still need to create a `Client` object, but as we have already created a cluster we can pass that directly to our client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del client, cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote clusters via SLURM\n",
    "We use SLURM on Perlmutter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    cores=2,\n",
    "    memory=\"1GB\",\n",
    "    walltime=\"01:00:00\",\n",
    "    job_extra_directives=[f\"--qos=shared\", f\"-C cpu\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the URL of the Dask Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.dashboard_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And port-forward it to our own computer:\n",
    "```\n",
    "ssh -N -L 8000:localhost:8787 dnoll@perlmutter\n",
    "```\n",
    "\n",
    "And take a look at it in our local browser:\n",
    "```\n",
    "http://localhost:8000/status\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Cluster\n",
    "\n",
    "With some cluster managers it is possible to scale the cluster dynamically.\n",
    "\n",
    "You can do this explicitly using `cluster.scale` function:\n",
    "```\n",
    "cluster.scale(jobs=10)  # Launch 10 jobs\n",
    "```\n",
    "or via specifying the total amount of cores\n",
    "```\n",
    "cluster.scale(cores=48)\n",
    "```\n",
    "or memory\n",
    "```\n",
    "cluster.scale(memory=\"200 GB\")\n",
    "```\n",
    "\n",
    "Or dynamically using `cluster.adapt`, find more [here](https://docs.dask.org/en/latest/adaptive.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect a client and compute\n",
    "Next, let's connect a client to this cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import LocalCluster, Client\n",
    "\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And do some computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def function(x):\n",
    "    time.sleep(3)\n",
    "    return x+1\n",
    "\n",
    "futures = client.map(function, list(range(10)))\n",
    "results = client.gather(futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close your Dask Cluster\n",
    "Afterwards we scale down the cluster and close client and cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(0)\n",
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More info\n",
    "\n",
    "You can find more info and some 'official scripts' for Dask @ Perlmutter here https://docs.nersc.gov/analytics/dask/ and more examples here https://gitlab.com/NERSC/nersc-notebooks/-/tree/main/perlmutter/dask."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "dask-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
